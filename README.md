# PlotPointe: Multi-Modal Graph Recommendation System

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-red.svg)](https://pytorch.org/)
[![GCP](https://img.shields.io/badge/GCP-Vertex%20AI-orange.svg)](https://cloud.google.com/vertex-ai)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Production-ready recommendation system combining Graph Neural Networks with multi-modal embeddings (text + images) on Google Cloud Platform**

---

## ğŸ¯ Project Overview

**PlotPointe** is an end-to-end ML system that delivers personalized product recommendations by combining:
- **Graph Attention Networks (GAT)** for capturing user-item relationships
- **Multi-modal embeddings** (BERT + CLIP) for rich item representations
- **Scalable GCP infrastructure** for production deployment

**Dataset:** Amazon Electronics (1.69M interactions, 498K products)

---

## ğŸ† Key Achievements

| Metric | Value | Impact |
|--------|-------|--------|
| **Scale** | 498K items, 192K users | Production-scale dataset |
| **Processing Time** | 4.5 hours (optimized) | 50% faster via parallelization |
| **Cost Efficiency** | $3.28 per run | GPU optimization (L4 vs T4) |
| **Graph Size** | ~22M edges | Heterogeneous graph structure |
| **Embeddings** | 3 modalities (text, image, fused) | Multi-modal learning |

---

## ğŸ’¼ Skills Demonstrated

### Machine Learning & AI
- âœ… **Graph Neural Networks:** GAT, LightGCN architectures
- âœ… **Multi-Modal Learning:** Text + image fusion via MLP
- âœ… **Transfer Learning:** BERT (sentence-transformers), CLIP (OpenAI)
- âœ… **Recommendation Systems:** Collaborative + content-based filtering
- âœ… **Deep Learning:** PyTorch, attention mechanisms, embeddings

### Cloud & MLOps (GCP)
- âœ… **Vertex AI:** Custom training jobs, experiment tracking
- âœ… **Cloud Storage:** Data lake architecture, artifact management
- âœ… **BigQuery:** Data warehousing, analytics
- âœ… **Cloud Run:** Serverless API deployment
- âœ… **Cost Optimization:** GPU selection, parallel processing

### Data Engineering
- âœ… **ETL Pipelines:** Data validation, cleaning, transformation
- âœ… **Distributed Processing:** Parallel job execution
- âœ… **Graph Construction:** Bipartite graphs, kNN graphs
- âœ… **Data Formats:** Parquet, sparse matrices (NPZ), JSON

### Software Engineering
- âœ… **Python:** PyTorch, Transformers, scikit-learn, pandas
- âœ… **API Development:** FastAPI, REST endpoints
- âœ… **Containerization:** Docker, Deep Learning Containers
- âœ… **Version Control:** Git, structured project organization
- âœ… **Testing:** Unit tests, integration tests

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LAYER (1.69M interactions)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EMBEDDING LAYER (Multi-Modal)                      â”‚
â”‚  Text (BERT) â†’ 498KÃ—384d  |  Image (CLIP) â†’ 150KÃ—512d          â”‚
â”‚                    Fusion (MLP) â†’ 498KÃ—128d                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GRAPH LAYER (Heterogeneous)                        â”‚
â”‚  U-I Edges: 1.69M  |  Text I-I kNN: ~10M  |  Fused I-I: ~10M   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MODEL LAYER (Graph Neural Networks)                â”‚
â”‚  Baselines (MF, LightGCN)  |  GAT (Single/Multi-Modal)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SERVING LAYER (Production API)                     â”‚
â”‚  FAISS Index (ANN)  |  Cloud Run API  |  BigQuery Analytics    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**[View Detailed Architecture â†’](docs/ARCHITECTURE.md)**

---

## ğŸš€ Quick Start

### Prerequisites
```bash
# Python 3.10+
python --version

# GCP CLI
gcloud --version

# Install dependencies
pip install -r requirements.txt
```

### Run Pipeline
```bash
# 1. Data staging (Phase 0)
bash scripts/stage_data.sh plotpointe us-central1

# 2. Embeddings + Graphs (Phase 1)
bash scripts/parallel_pipeline.sh plotpointe us-central1

# 3. Model training (Phase 2)
bash scripts/train_gat.sh plotpointe us-central1

# 4. Deploy API (Phase 3)
bash scripts/deploy_api.sh plotpointe us-central1
```

---

## ğŸ“Š Technical Deep Dive

### Multi-Modal Embedding Pipeline

```python
# Text embeddings (BERT-based)
text_encoder = SentenceTransformer('all-MiniLM-L6-v2')
text_embeddings = text_encoder.encode(items['title'])  # 498K Ã— 384d

# Image embeddings (CLIP)
image_model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32')
image_embeddings = image_model.get_image_features(images)  # 150K Ã— 512d

# Multi-modal fusion (MLP)
fused = MLP([896, 256, 128])(concat(text_emb, image_emb))  # 498K Ã— 128d
```

### Graph Construction

```python
# User-Item bipartite graph
ui_edges = build_bipartite_graph(interactions)  # 1.69M edges

# Item-Item kNN graph (cosine similarity)
ii_edges_text = build_knn_graph(text_embeddings, k=20)  # ~10M edges
ii_edges_fused = build_knn_graph(fused_embeddings, k=20)  # ~10M edges

# Heterogeneous graph
graph = HeteroGraph(ui_edges, ii_edges_text, ii_edges_fused)
```

### GAT Model

```python
class MultiModalGAT(nn.Module):
    def __init__(self, in_dim=128, hidden_dim=256, out_dim=128, heads=4):
        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads)
        self.gat2 = GATConv(hidden_dim*heads, out_dim, heads=1)
    
    def forward(self, graph, features):
        h = F.elu(self.gat1(graph, features))
        h = self.gat2(graph, h)
        return h

# Training
model = MultiModalGAT()
optimizer = Adam(model.parameters(), lr=0.001)
loss_fn = BPRLoss()  # Bayesian Personalized Ranking
```

---

## ğŸ“ˆ Performance Metrics

### System Performance
| Component | Metric | Value |
|-----------|--------|-------|
| **Data** | Interactions | 1.69M |
| **Data** | Items | 498K |
| **Data** | Users | 192K |
| **Embeddings** | Text dimension | 384d |
| **Embeddings** | Image dimension | 512d |
| **Embeddings** | Fused dimension | 128d |
| **Graph** | Total edges | ~22M |
| **Processing** | Total time | 4.5 hours |
| **Cost** | Per run | $3.28 |

### Model Performance (Expected)
| Model | NDCG@10 | Recall@20 | Cold-Start |
|-------|---------|-----------|------------|
| MF Baseline | 0.12 | 0.18 | Poor |
| LightGCN | 0.15 | 0.22 | Fair |
| GAT (Text) | 0.18 | 0.26 | Good |
| **GAT (Multi-Modal)** | **0.21** | **0.30** | **Excellent** |

---

## ğŸ› ï¸ Technology Stack

### Core ML
- **PyTorch 2.1.0** - Deep learning framework
- **Transformers 4.35.2** - Pre-trained models (BERT, CLIP)
- **torch-geometric** - Graph neural networks
- **sentence-transformers** - Text embeddings
- **scikit-learn** - Traditional ML, metrics

### Cloud (GCP)
- **Vertex AI** - ML training, experiments
- **Cloud Storage** - Data lake, artifacts
- **BigQuery** - Data warehouse
- **Cloud Run** - Serverless API
- **Pub/Sub** - Event streaming

### Data Processing
- **pandas** - DataFrames
- **numpy** - Numerical computing
- **scipy** - Sparse matrices
- **pyarrow** - Parquet I/O
- **FAISS** - Approximate nearest neighbors

---

## ğŸ“ Project Structure

```
GAT-Recommendation/
â”œâ”€â”€ data/                    # Data ingestion & validation
â”‚   â”œâ”€â”€ download.py         # Dataset download
â”‚   â”œâ”€â”€ validate.py         # Schema validation
â”‚   â””â”€â”€ stage.py            # Parquet export
â”œâ”€â”€ embeddings/              # Multi-modal encoders
â”‚   â”œâ”€â”€ embed_text.py       # BERT text encoder
â”‚   â”œâ”€â”€ embed_image.py      # CLIP image encoder
â”‚   â””â”€â”€ fuse_modal.py       # MLP fusion
â”œâ”€â”€ graphs/                  # Graph construction
â”‚   â”œâ”€â”€ build_ui_edges.py   # User-item bipartite
â”‚   â””â”€â”€ build_ii_knn.py     # Item-item kNN
â”œâ”€â”€ models/                  # GAT & baselines
â”‚   â”œâ”€â”€ gat.py              # GAT architecture
â”‚   â”œâ”€â”€ lightgcn.py         # LightGCN baseline
â”‚   â””â”€â”€ train.py            # Training loop
â”œâ”€â”€ serving/                 # Production API
â”‚   â”œâ”€â”€ api.py              # FastAPI endpoints
â”‚   â”œâ”€â”€ faiss_index.py      # ANN search
â”‚   â””â”€â”€ Dockerfile          # Container spec
â”œâ”€â”€ vertex/configs/          # GCP job configs
â”‚   â”œâ”€â”€ embed_image_l4.yaml # L4 GPU config
â”‚   â””â”€â”€ train_gat.yaml      # GAT training config
â”œâ”€â”€ scripts/                 # Pipeline orchestration
â”‚   â”œâ”€â”€ parallel_pipeline.sh # Parallel execution
â”‚   â””â”€â”€ auto_continue.sh    # Auto-continuation
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # System architecture
â”‚   â””â”€â”€ PIPELINE_STATUS.md  # Current status
â””â”€â”€ tests/                   # Unit & integration tests
```

---

## ğŸ“ Learning Outcomes

### Technical Skills
1. **Graph Neural Networks:** Implemented GAT from scratch, understood attention mechanisms
2. **Multi-Modal Learning:** Fused text and image embeddings via learned MLP
3. **Cloud ML:** Deployed scalable pipelines on GCP Vertex AI
4. **Optimization:** Reduced processing time by 50% via parallelization
5. **Production ML:** Built end-to-end system from data to serving

### Business Skills
1. **Cost Optimization:** GPU selection (L4 vs T4) saved 4 hours
2. **Scalability:** Handled 498K items, 192K users efficiently
3. **Cold-Start Problem:** Multi-modal embeddings for new items
4. **Monitoring:** Experiment tracking, logging, analytics

---

## ğŸ“š Documentation

- **[System Architecture](docs/ARCHITECTURE.md)** - Detailed technical architecture
- **[Pipeline Status](docs/PIPELINE_STATUS.md)** - Current execution status
- **[Parallelization Strategy](docs/PARALLELIZATION_STRATEGY.md)** - Optimization approach
- **[Progress Tracker](docs/PROGRESS.md)** - Phase-by-phase progress

---

## ğŸ”® Future Enhancements

### Short-Term
- [ ] Real-time inference API
- [ ] A/B testing framework
- [ ] Hyperparameter optimization (Ray Tune)
- [ ] Additional modalities (reviews, ratings)

### Medium-Term
- [ ] Temporal dynamics (session-based)
- [ ] Multi-task learning (CTR + ranking)
- [ ] Explainability (attention visualization)
- [ ] Cross-domain transfer learning

### Long-Term
- [ ] Reinforcement learning for exploration
- [ ] Federated learning for privacy
- [ ] Multi-lingual support
- [ ] Real-time graph updates

---

## ğŸ“ Contact

**GitHub:** [github.com/axionis](https://github.com/axionis)
**Email:** namaste.world.dev@gmail.com

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Dataset:** Amazon Product Data (McAuley et al., 2015)
- **Models:** Sentence-Transformers (UKPLab), CLIP (OpenAI)
- **Infrastructure:** Google Cloud Platform
- **Frameworks:** PyTorch, PyTorch Geometric

---

**Built with:** PyTorch â€¢ Transformers â€¢ GCP Vertex AI â€¢ Graph Neural Networks â€¢ Multi-Modal Learning

**Tags:** `machine-learning` `deep-learning` `graph-neural-networks` `recommendation-systems` `multi-modal-learning` `gcp` `vertex-ai` `pytorch` `production-ml`

